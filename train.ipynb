{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f5a71d-1453-4f8e-ae03-b8953f6cbc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# pd.options.plotting.backend = \"plotly\"\n",
    "import random\n",
    "from glob import glob\n",
    "import os, shutil\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import copy\n",
    "# import joblib\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "from IPython import display as ipd\n",
    "\n",
    "# visualization\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Sklearn\n",
    "# from sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\n",
    "\n",
    "# PyTorch \n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "#torchio\n",
    "import torchio as tio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce990be-8a4c-4248-a8e9-5b7a02d7e263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class indices\n",
    "\n",
    "LARGE_BOWEL = 0\n",
    "SMALL_BOWEL = 1\n",
    "STOMACH = 2\n",
    "MASK_INDICES = {'large_bowel': LARGE_BOWEL, 'small_bowel':SMALL_BOWEL, 'stomach':STOMACH}\n",
    "DATA_SIZE = 274"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be45d59f-7ed0-4000-b351-6ad3564f64e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed          = 101\n",
    "    debug         = False # set debug=False for Full Training\n",
    "    train_bs      = 1\n",
    "    valid_bs      = 1\n",
    "    image_size    = [128, 128, 128] # Depth, Width, Height\n",
    "    whf_pool_size = 4\n",
    "    epochs        = 64\n",
    "    lr            = 2e-3\n",
    "    scheduler     = 'CosineAnnealingLR'\n",
    "    warmup_epochs = 0\n",
    "    wd            = 1e-4\n",
    "    n_accumulate  = max(1, 8//train_bs)\n",
    "    n_fold        = 5\n",
    "    device        = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    min_lr        = 1e-6\n",
    "    T_max         = int(DATA_SIZE/train_bs/n_accumulate*epochs)+50\n",
    "    T_0           = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff64c504-b724-4d4c-8a2a-b9678ee25959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed = 42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    print('> SEEDING DONE')\n",
    "    \n",
    "set_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f546e0-a183-403f-854d-c7e60d375083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scans(scan_path):\n",
    "    image_files = [f for f in os.listdir(scan_path) if os.path.isfile(os.path.join(scan_path, f))]\n",
    "    image_files.sort(key=lambda x: int(x.split('_')[1]))\n",
    "    \n",
    "    scan_slices = []\n",
    "    for img_file in image_files:\n",
    "        img_file_path = os.path.join(scan_path, img_file)\n",
    "        scan_slice = cv2.imread(img_file_path, cv2.IMREAD_UNCHANGED)\n",
    "        scan_slice = scan_slice.astype('float32')\n",
    "        scan_slices.append(scan_slice)\n",
    "    \n",
    "    img = np.stack(scan_slices)\n",
    "    max_val = np.max(img)\n",
    "    if max_val:\n",
    "        img /= max_val\n",
    "\n",
    "    return img\n",
    "\n",
    "def load_mask(path):\n",
    "    mask = np.load(path).transpose([3,0,1,2])\n",
    "    mask = mask.astype('float32')\n",
    "    return mask\n",
    "\n",
    "# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da8a770-7c7e-433e-9369-16cfb65011f0",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a7903e-7894-4579-906e-8abfafcf2aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_batch(imgs, msks, depth, size=3):\n",
    "    plt.figure(figsize=(5*5, 5))\n",
    "    for idx in range(size):\n",
    "        plt.subplot(1, 5, idx+1)\n",
    "        img = imgs[idx, depth].permute((1, 2, 0)).numpy()*255.0\n",
    "        img = img.astype('uint8')\n",
    "        msk = msks[idx, depthm].permute((1, 2, 0)).numpy()*255.0\n",
    "        show_img(img, msk)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d6b56f-1000-4978-8912-a6f9c38a4c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dimension_order_to_c_z_x_y = tio.Lambda(lambda x: torch.permute(x,(0,3,1,2)), types_to_apply=[tio.INTENSITY, tio.LABEL])\n",
    "\n",
    "data_transforms = {\n",
    "    \"train\": tio.Compose(\n",
    "        [tio.RescaleIntensity(out_min_max=(0, 1)), \n",
    "         tio.Resize(target_shape=CFG.image_size, image_interpolation='linear', label_interpolation='nearest'), \n",
    "         tio.RandomFlip(axes=(0,1), p=0.2), \n",
    "         tio.RandomAffine(scales=(0.9, 1.2), degrees=15, p=0.2), \n",
    "         tio.OneOf([tio.RandomElasticDeformation(), tio.RandomMotion()], p=0.3), \n",
    "         tio.OneOf([tio.RandomGhosting(), tio.RandomSpike(), tio.RandomBlur()], p=0.3),\n",
    "         # set_dimension_order_to_c_z_x_y\n",
    "        ]\n",
    "    ),\n",
    "    \"valid\": tio.Compose(\n",
    "        [tio.RescaleIntensity(out_min_max=(0, 1)), \n",
    "         tio.Resize(target_shape=CFG.image_size, image_interpolation='linear', label_interpolation='nearest'),\n",
    "         # set_dimension_order_to_c_z_x_y\n",
    "        ]\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d9e82-c512-4c68-b0e6-e8a1bc58a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResizedSubject(tio.Subject):\n",
    "    def load(self):\n",
    "        super(ResizedSubject, self).load()\n",
    "        self['original_size'] = list(self['scan'][tio.DATA].shape)[1:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e1628d-bb80-4c59-b5eb-f70045bc22c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_reader(scan_path):\n",
    "    image_files = [f for f in os.listdir(scan_path) if os.path.isfile(os.path.join(scan_path, f)) and f.endswith('.png')]\n",
    "    image_files.sort(key=lambda x: int(x.split('_')[1]))\n",
    "    \n",
    "    scan_slices = []\n",
    "    for img_file in image_files:\n",
    "        img_file_path = os.path.join(scan_path, img_file)\n",
    "        scan_slice = cv2.imread(img_file_path, cv2.IMREAD_UNCHANGED)\n",
    "        scan_slice = np.expand_dims(scan_slice, axis=0)\n",
    "        scan_slice = scan_slice.astype('float32')\n",
    "        scan_slices.append(scan_slice)\n",
    "    \n",
    "    img = np.stack(scan_slices, axis=-1)\n",
    "\n",
    "    return img, None\n",
    "\n",
    "def mask_reader(path):\n",
    "    mask = np.load(path).transpose([3,0,1,2])\n",
    "    mask = mask.astype('float32')\n",
    "    return mask, None\n",
    "\n",
    "def get_subject(case_day, scan_path, mask_path=None):\n",
    "    \n",
    "    if not mask_path:\n",
    "        return ResizeSubject(\n",
    "            case_day=case_day, \n",
    "            scan=tio.ScalarImage(path=scan_path, reader=scan_reader),\n",
    "        )\n",
    "\n",
    "    return ResizedSubject(\n",
    "        case_day=case_day,\n",
    "        scan=tio.ScalarImage(path=scan_path, reader=scan_reader),\n",
    "        label=tio.LabelMap(path=mask_path, reader=mask_reader),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb9c427-b0ee-41cf-98dd-d4263934ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for assigning fold to Data frame rows\n",
    "\n",
    "def assign_fold_to_df(df, num_folds=5):\n",
    "    num_rows = len(df)\n",
    "    folds = np.zeros(num_rows, dtype='uint8')\n",
    "    fold_vals = [i for i in range(num_folds)]\n",
    "    indices = [i for i in range(num_rows)]\n",
    "    random.shuffle(indices)\n",
    "    random.shuffle(fold_vals)\n",
    "    for i in indices:\n",
    "        folds[i] = fold_vals[i % num_folds]\n",
    "\n",
    "     # not shuffling fold_vals will cause some fold indices to always get less number of items than other fold indices.\n",
    "    # EX: number of items is 2, and num_folds = 3. Assigning fold index with order [0,1,2] will make only fold-0 and fold-1 get an item, while fold-2 has 0 item.\n",
    " \n",
    "    df['fold'] = folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac6d215-6498-4405-809b-b190a0f07734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loaders(df, fold, debug=False):\n",
    "    train_df = df.query(\"fold!=@fold\").reset_index(drop=True)\n",
    "    valid_df = df.query(\"fold==@fold\").reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = tio.SubjectsDataset(\n",
    "        [get_subject(row['case_day'], row['image_path'], row['mask_path']) for _, row in train_df.iterrows()], \n",
    "        transform=data_transforms['train']\n",
    "    )\n",
    "    valid_dataset = tio.SubjectsDataset(\n",
    "        [get_subject(row['case_day'], row['image_path'], row['mask_path']) for _, row in valid_df.iterrows()], \n",
    "        transform=data_transforms['train']\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CFG.train_bs if not debug else 1, \n",
    "                              num_workers=4, shuffle=True, pin_memory=False, drop_last=False)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CFG.valid_bs if not debug else 1, \n",
    "                              num_workers=4, shuffle=False, pin_memory=False)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4b5a7f-c5f8-4f8a-81ac-a7d73803ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data frame\n",
    "\n",
    "df_train = pd.read_csv('./input/uw-madison-gi-tract-image-segmentation/train.csv')\n",
    "train_path = './input/uw-madison-gi-tract-image-segmentation/train'\n",
    "df_train['case_day'] = df_train['id'].map(lambda x: x.split('_slice')[0])\n",
    "df_train.drop(columns=['class', 'segmentation', 'id'], inplace=True)\n",
    "df_train.drop_duplicates(inplace=True)\n",
    "df_train['image_path'] = df_train['case_day'].map(lambda x: f'{train_path}/' + x.split('_')[0] + f'/{x}/scans')\n",
    "df_train['mask_path'] =  df_train['case_day'].map(lambda x: f'{train_path}/' + x.split('_')[0] + f'/{x}/masks3D/{x}.npy')\n",
    "assign_fold_to_df(df_train)\n",
    "df_train.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d045a67-a7d7-4ca7-9dcb-34eb4856b3df",
   "metadata": {},
   "source": [
    "### Compare with Transformed Data\n",
    "\n",
    "Create Dataset and compare with the transformed image.\\\n",
    "You may want to temporaruily remove any spatial transformation that moves the original data along z-axis, \\\n",
    "because bellow code compares image with fixed slice number(z-axis value).\n",
    "\n",
    "Skip bellow section, if you are done dataset debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc84380-6f2e-4260-8306-8411e0c19f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692a7d70-b057-4dea-9c32-3815c727b72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_dataset = tio.SubjectsDataset(\n",
    "        [get_subject(row['case_day'], row['image_path'], row['mask_path']) for _, row in df_train.iterrows()], \n",
    "        transform=data_transforms['train']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db98b53-48fa-4def-ad49-c728bdecb3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subject\n",
    "# By selecting an item with indexing, data transformation is perofrmed in bellow code.\n",
    "# It will be performed again if you execute bellow code again even with the same index value.\n",
    "subject = subject_dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0f77a9-713b-4023-800c-3635419950da",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_num = 113 # z-axis value\n",
    "case_day = subject['case_day']\n",
    "original_size = subject['original_size']\n",
    "case_day, original_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e4d747-7ffd-4956-b59d-b27a0ef377b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the original image\n",
    "\n",
    "df_row = df_train.loc[df_train['case_day'] == case_day].iloc[0]\n",
    "image_path = glob.glob(df_row['image_path'] + f'/slice_{str(slice_num).zfill(4)}_*.png')[0]\n",
    "image = plt.imread(image_path)\n",
    "mask = load_mask(df_row['mask_path'])[:, :, :, slice_num-1]\n",
    "mask[1] *= 2\n",
    "mask[2] *= 3\n",
    "mask_sum = mask.sum(axis=0)\n",
    "fig, ax = plt.subplots(1,3,figsize=(10,6))\n",
    "ax[0].imshow(image)\n",
    "ax[1].imshow(mask_sum)\n",
    "ax[2].imshow(image,'gray')\n",
    "ax[2].imshow(mask_sum, alpha=0.5)\n",
    "plt.show()\n",
    "mask.sum(axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c693f6a-f803-4eac-a44e-658d5b3a2941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show trnsformed image\n",
    "resized_slice_num = slice_num * CFG.image_size[2] // len(glob.glob(df_row['image_path'] + f'/slice_*.png')) \n",
    "image = subject['scan'][tio.DATA][0][:,:, resized_slice_num -1]\n",
    "mask = subject['label'][tio.DATA][:,:,:, resized_slice_num - 1]\n",
    "mask[1] *= 2\n",
    "mask[2] *= 3\n",
    "mask_sum = mask.sum(axis=0)\n",
    "fig, ax = plt.subplots(1,3,figsize=(10,6))\n",
    "ax[0].imshow(image)\n",
    "ax[1].imshow(mask_sum)\n",
    "ax[2].imshow(image,'gray')\n",
    "ax[2].imshow(mask_sum, alpha=0.5)\n",
    "plt.show()\n",
    "mask.sum(axis=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ca055d-8dd8-4194-a469-36c0a1bf4b87",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a14fb9-e54a-4578-9897-93702a31b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segmtation_indices(mask):\n",
    "    \"\"\"\n",
    "    :mask: (C x W x H x D) Tensor of the probability map of the estimation.\n",
    "    :return: List of List of Tensors of the Ground Truth points.\n",
    "                   The outer most list must be of size B as in prob_map.\n",
    "                   The second outer most list must be of size C.\n",
    "                   Each element in the second outer most list must be a 2D Tensor,\n",
    "                   where each row is the (x, y, z), i.e, (col, row, depth) of a GT point.\n",
    "    \"\"\"\n",
    "    num_classes = mask.size()[0]\n",
    "    mask_indices = []\n",
    "    for i in range(num_classes):\n",
    "        mask_indices.append((mask[i] > 0).nonzero())\n",
    "    \n",
    "    return mask_indices\n",
    "        \n",
    "\n",
    "def double_conv_block(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv3d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
    "        nn.BatchNorm3d(out_channels),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv3d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "        nn.BatchNorm3d(out_channels),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=3, features =[64, 128, 256, 512]):\n",
    "        super(UNet3D, self).__init__()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "\n",
    "        #down part of UNet\n",
    "        for feature in features:\n",
    "            self.downs.append(double_conv_block(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        #upsample part of UNet\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "              nn.ConvTranspose3d(feature*2, feature, kernel_size=2, stride=2)\n",
    "            )\n",
    "            self.ups.append(double_conv_block(feature*2, feature))\n",
    "\n",
    "        self.bottleneck = double_conv_block(features[-1], features[-1]*2)\n",
    "        self.final_conv = nn.Sequential(nn.Conv3d(features[0], out_channels, kernel_size=1),  nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "\n",
    "            # if x.shape != skip_connection.shape:\n",
    "            #     x = TF.resize(x, size=skip_connection.shape[2:])\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b2d9e-8460-4fd9-a236-1a3e9ae3bd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = UNet3D()\n",
    "    model.to(CFG.device)\n",
    "    return model\n",
    "\n",
    "def load_model(path):\n",
    "    model = build_model()\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9294608a-abf9-4089-921c-34788129e070",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21337543-ce88-492a-86bd-50c1c9e38749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _assert_no_grad(variables_list):\n",
    "    for variables in variables_list:\n",
    "        for var in variables:\n",
    "            assert not var.requires_grad, \\\n",
    "                \"nn criterions don't compute the gradient w.r.t. targets - please \" \\\n",
    "                \"mark these variables as volatile or not requiring gradients\"\n",
    "\n",
    "class DiceLoss(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes=num_classes\n",
    "        super(DiceLoss, self).__init__()\n",
    "    def forward(self, pred, target):\n",
    "        batch_size = pred.shape[0]\n",
    "        smooth = 0.001\n",
    "        iflat = pred.contiguous().view(batch_size, -1)\n",
    "        tflat = target.contiguous().view(batch_size, -1)\n",
    "        intersection = (iflat * tflat).sum(-1)\n",
    "        A_sum = torch.sum(iflat * iflat, -1)\n",
    "        B_sum = torch.sum(tflat * tflat, -1)\n",
    "        return (1 - ((2. * intersection + smooth) / (A_sum + B_sum + smooth) )).mean()\n",
    "\n",
    "\n",
    "class WeightedHausdorffLoss(torch.nn.Module):\n",
    "    def __init__(self, num_classes, resized_shape, alpha=-4.0, return_by_class=False, device=torch.device('cpu')):\n",
    "        self.alpha = alpha\n",
    "        self.return_by_class = return_by_class\n",
    "        self.width, self.height, self.depth = resized_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.resized_size = torch.tensor(\n",
    "            resized_shape,\n",
    "            dtype=torch.get_default_dtype(), \n",
    "            device=device\n",
    "        )\n",
    "        self.n_pixels = np.prod(resized_shape)\n",
    "        \n",
    "        self.all_pixel_locations = torch.from_numpy(\n",
    "            np.indices(resized_shape, dtype=np.int32).reshape(3,-1).transpose()\n",
    "        ).to(device=device, dtype=torch.get_default_dtype())\n",
    "        self.const_one = torch.tensor(1.0).to(device=device, dtype=torch.get_default_dtype())\n",
    "        super(WeightedHausdorffLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, prob_map, gt, orig_sizes):\n",
    "        \"\"\"\n",
    "        Compute the Weighted Hausdorff Distance function\n",
    "        between the estimated probability map and ground truth points.\n",
    "        The output is the WHD averaged through all the batch.\n",
    "        :param prob_map: (B x C x W x H x D) Tensor of the probability map of the estimation.\n",
    "                         B is batch size, C is number of classes, H is height, W is width and D is depth.\n",
    "                         Values must be between 0 and 1.\n",
    "        :param gt: List of List of Tensors of the Ground Truth points.\n",
    "                   The outer most list must be of size B as in prob_map.\n",
    "                   The second outer most list must be of size C.\n",
    "                   Each element in the second outer most list must be a 2D Tensor,\n",
    "                   where each row is the (x, y, z), i.e, (col, row, depth) of a GT point.\n",
    "        :param orig_sizes: Bx3 Tensor containing the size\n",
    "                           of the original images.\n",
    "                           B is batch size.\n",
    "                           The size must be in (width, height, depth) format.\n",
    "        :return: Single-scalar Tensor with the Weighted Hausdorff Distance.\n",
    "                 If self.return_2_terms=True, then return a tuple containing\n",
    "                 the two terms of the Weighted Hausdorff Distance.\n",
    "        \"\"\"\n",
    "\n",
    "        _assert_no_grad(gt)\n",
    "\n",
    "        assert prob_map.dim() == 5, 'The probability map shape must be (B x C x W x H x D)'\n",
    "        assert prob_map.size()[1:5] == (self.num_classes, self.width, self.height, self.depth), \\\n",
    "        f'prob_map size is {prob_map.size()[1:5]}, it must have size {(self.num_classes, self.width, self.height, self.depth)}'\n",
    "\n",
    "        batch_size = prob_map.shape[0]\n",
    "        assert batch_size == len(gt)\n",
    "\n",
    "        distances_by_class = [[] for _ in range(self.num_classes)]\n",
    "    \n",
    "        for batch_index in range(batch_size):\n",
    "            orig_size_b = orig_sizes[batch_index, :]\n",
    "            norm_factor = (orig_size_b/self.resized_size)\n",
    "            max_dist = (orig_size_b ** 2).sum().sqrt()\n",
    "            for class_index in range(self.num_classes):\n",
    "                # One by one\n",
    "                prob_map_b = prob_map[batch_index, class_index]\n",
    "                gt_b = gt[batch_index][class_index]\n",
    "\n",
    "                # Corner case: no GT points\n",
    "                if gt_b.size()[0] == 0:\n",
    "                    # term_1 = max_dist\n",
    "                    # term_2 = 0\n",
    "                    distances_by_class[class_index].append(self.const_one)\n",
    "                    continue\n",
    "\n",
    "                # Pairwise distances between all possible locations and the GTed locations\n",
    "                n_gt_pts = gt_b.size()[0]\n",
    "                \n",
    "                # normalized_x has shape (width * height * depth, 3)\n",
    "                # normalized_y has shape (number of masked points, 3)\n",
    "                normalized_x = norm_factor * self.all_pixel_locations\n",
    "                normalized_y = norm_factor * gt_b\n",
    "\n",
    "                # normalized_x.unsqueeze(1) has shape (width * height * depth, 1, 3)\n",
    "                # normalized_y.unsqueeze(0) has shape (1, number of true segmented points, 3)\n",
    "                # diff has shape (width * height * depth, number of true segmented points, 3)\n",
    "                diffs = normalized_x.unsqueeze(1) - normalized_y.unsqueeze(0)\n",
    "                \n",
    "                # distances has shape (width * height * depth, number of true segmented points)\n",
    "                # normalize the distance with max distance \n",
    "                distance_matrix = torch.sum(diffs ** 2, -1).sqrt() / max_dist\n",
    "\n",
    "                # Reshape probability map as a long column vector,\n",
    "                # and prepare it for multiplication\n",
    "                p = prob_map_b.view(prob_map_b.nelement())\n",
    "                total_x_weight = p.sum()\n",
    "\n",
    "                # Weighted Hausdorff Distance\n",
    "                term_1 = (1 / (total_x_weight + 1e-6)) * torch.sum(p * torch.min(distance_matrix, 1)[0])\n",
    "                \n",
    "                p = p.view(-1, 1)\n",
    "                weighted_distance_matrix = (1 - p) + p*distance_matrix\n",
    "                \n",
    "                # get generalized mean\n",
    "                generalized_mean = torch.mean((weighted_distance_matrix + 1e-6)**self.alpha, 0)**(1./self.alpha)\n",
    "                term_2 = torch.mean(generalized_mean)\n",
    "                \n",
    "                result = term_1 + term_2\n",
    "                distances_by_class[class_index].append(result)\n",
    "\n",
    "        result = torch.stack(\n",
    "            [distances_by_class[class_index][batch_index] for batch_index in range(batch_size) for class_index in range(self.num_classes)]\n",
    "        ).view(batch_size, self.num_classes)\n",
    "        \n",
    "        if self.return_by_class:\n",
    "            return result.mean(dim=0) \n",
    "\n",
    "        return result.mean(dim=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22efdf41-dfdb-4952-95b5-a7adf7b9daaa",
   "metadata": {},
   "source": [
    "## Test Run"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d9550f88-583a-472e-ab12-0847d98f9149",
   "metadata": {},
   "source": [
    "train_loader, valid_loader = prepare_loaders(df_train, fold=0, debug=True)\n",
    "inputs = None\n",
    "targets = None\n",
    "case_days = None\n",
    "original_sizes = None\n",
    "subjects = None\n",
    "for subjects_batch in train_loader:\n",
    "    subjects = subjects_batch\n",
    "    inputs = subjects_batch['scan'][tio.DATA]\n",
    "    targets = subjects_batch['label'][tio.DATA]\n",
    "    case_days = subjects_batch['case_day']\n",
    "    original_sizes = subjects_batch['original_size']\n",
    "\n",
    "    break\n",
    "\n",
    "x = subjects_batch['scan'][tio.DATA]\n",
    "y = subjects_batch['label'][tio.DATA]\n",
    "case_days = subjects_batch['case_day']\n",
    "original_sizes = torch.stack(subjects_batch['original_size']).transpose(0,1).to(CFG.device)\n",
    "\n",
    "segmentation_indices = []\n",
    "for i in range(CFG.train_bs):\n",
    "    class_segmentation_indices = [item.to(CFG.device) for item in get_segmtation_indices(y[i])]\n",
    "    segmentation_indices.append(class_segmentation_indices)\n",
    "    \n",
    "model = UNet3D()\n",
    "model.to(CFG.device)\n",
    "x = x.to(CFG.device)\n",
    "y = y.to(CFG.device)\n",
    "preds = model(x)\n",
    "whf_loss = WeightedHausdorffLoss(3, CFG.image_size, alpha=-1.0, device=CFG.device)\n",
    "dice_loss = DiceLoss(3)\n",
    "loss = 0.4 * dice_loss(preds, y)  + 0.6 * whf_loss(preds, segmentation_indices, original_sizes)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd8e4bb-1556-4ab1-ac68-8f9d40088d98",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1341151-9a7f-4739-a401-01b454e30fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch, whf):\n",
    "    model.train()\n",
    "    dice = DiceLoss(3)\n",
    "    scaler = amp.GradScaler()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    running_dice_loss = 0.0\n",
    "    running_whf_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Train ', ncols=150)\n",
    "    \n",
    "    for step, subjects_batch in pbar:\n",
    "        images = subjects_batch['scan'][tio.DATA]\n",
    "        masks = subjects_batch['label'][tio.DATA]\n",
    "        original_sizes = subjects_batch['original_size']\n",
    "        original_sizes = torch.stack(subjects_batch['original_size']).transpose(0,1)\n",
    "        case_days = subjects_batch['case_day']\n",
    "        \n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        masks  = masks.to(device, dtype=torch.float)\n",
    "        original_sizes = original_sizes.to(device, dtype=torch.float)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        mask_max_pool = nn.functional.max_pool3d(masks,CFG.whf_pool_size)\n",
    "        segmentation_indices = []\n",
    "        for i in range(batch_size):\n",
    "            class_segmentation_indices = [item.to(CFG.device) for item in get_segmtation_indices(mask_max_pool[i])]\n",
    "            segmentation_indices.append(class_segmentation_indices)\n",
    "        \n",
    "        with amp.autocast(enabled=True):\n",
    "            y_preds = model(images)\n",
    "            dice_loss = dice(y_preds, masks)\n",
    "            whf_loss = whf(nn.functional.avg_pool3d(y_preds, CFG.whf_pool_size), segmentation_indices, original_sizes)\n",
    "            loss = 0.4 * dice_loss + 0.6 * whf_loss\n",
    "            \n",
    "        scaler.scale(loss / CFG.n_accumulate).backward()\n",
    "    \n",
    "        if (step + 1) % CFG.n_accumulate == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "                \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        running_dice_loss += (dice_loss.item() * batch_size)\n",
    "        running_whf_loss += (whf_loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        epoch_dice_loss = running_dice_loss / dataset_size\n",
    "        epoch_whf_loss = running_whf_loss / dataset_size\n",
    "        \n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(train_loss=f'{epoch_loss:0.4f}', dice_l=f'{dice_loss:0.4f}', whf_l=f'{epoch_whf_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_mem=f'{mem:0.2f} GB')\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe08882f-1c41-4c9b-8c83-511dd8ccdf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, thr=0.5, dim=(2,3,4), epsilon=0.001):\n",
    "    y_true = y_true.to(torch.float32)\n",
    "    y_pred = (y_pred>thr).to(torch.float32)\n",
    "    inter = (y_true*y_pred).sum(dim=dim)\n",
    "    den = y_true.sum(dim=dim) + y_pred.sum(dim=dim)\n",
    "    dice = ((2*inter+epsilon)/(den+epsilon)).mean(dim=(1,0))\n",
    "    return dice\n",
    "\n",
    "def iou_coef(y_true, y_pred, thr=0.5, dim=(2,3, 4), epsilon=0.001):\n",
    "    y_true = y_true.to(torch.float32)\n",
    "    y_pred = (y_pred>thr).to(torch.float32)\n",
    "    inter = (y_true*y_pred).sum(dim=dim)\n",
    "    union = (y_true + y_pred - y_true*y_pred).sum(dim=dim)\n",
    "    iou = ((inter+epsilon)/(union+epsilon)).mean(dim=(1,0))\n",
    "    return iou\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch, whf):\n",
    "    model.eval()\n",
    "    dice = DiceLoss(3)\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    running_dice_loss = 0.0\n",
    "    running_whf_loss = 0.0\n",
    "    \n",
    "    val_scores = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Valid ', ncols=150)\n",
    "   \n",
    "    for step, subjects_batch in pbar:\n",
    "        images = subjects_batch['scan'][tio.DATA]\n",
    "        masks = subjects_batch['label'][tio.DATA]\n",
    "        original_sizes = subjects_batch['original_size']\n",
    "        original_sizes = torch.stack(subjects_batch['original_size']).transpose(0,1)\n",
    "        case_days = subjects_batch['case_day']\n",
    "\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        masks  = masks.to(device, dtype=torch.float)\n",
    "        original_sizes = original_sizes.to(device, dtype=torch.float)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        mask_max_pool = nn.functional.max_pool3d(masks,CFG.whf_pool_size)\n",
    "        segmentation_indices = []\n",
    "        for i in range(batch_size):\n",
    "            class_segmentation_indices = [item.to(CFG.device) for item in get_segmtation_indices(mask_max_pool[i])]\n",
    "            segmentation_indices.append(class_segmentation_indices)\n",
    "        \n",
    "        y_preds  = model(images)\n",
    "        dice_loss = dice(y_preds, masks)\n",
    "        whf_loss = whf(nn.functional.avg_pool3d(y_preds, CFG.whf_pool_size), segmentation_indices, original_sizes)\n",
    "        loss = 0.4 * dice_loss + 0.6 * whf_loss\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        running_dice_loss += (dice_loss.item() * batch_size)\n",
    "        running_whf_loss += (whf_loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        epoch_dice_loss = running_dice_loss / dataset_size\n",
    "        epoch_whf_loss = running_whf_loss / dataset_size\n",
    "        \n",
    "        # y_pred = nn.Sigmoid()(y_pred)\n",
    "        val_dice = dice_coef(masks, y_preds).cpu().detach().numpy()\n",
    "        val_jaccard = iou_coef(masks, y_preds).cpu().detach().numpy()\n",
    "        val_scores.append([val_dice, val_jaccard])\n",
    "        \n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        pbar.set_postfix(valid_loss=f'{epoch_loss:0.4f}', dice_l=f'{dice_loss:0.4f}', whf_l=f'{epoch_whf_loss:0.4f}',\n",
    "                        gpu_memory=f'{mem:0.2f} GB')\n",
    "    val_scores = np.mean(val_scores, axis=0)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss, val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25fc259-35ee-4c51-a115-84969917e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(fold, model, whf_loss_func, optimizer, scheduler, device, num_epochs):\n",
    "    # To automatically log gradients\n",
    "    # wandb.watch(model, log_freq=100)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"cuda: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss      = -np.inf\n",
    "    best_epoch     = -1\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        print(f'Epoch {epoch}/{num_epochs}', end='')\n",
    "        train_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CFG.device, epoch=epoch, whf=whf_loss_func)\n",
    "        \n",
    "        val_loss, val_scores = valid_one_epoch(model, valid_loader, \n",
    "                                                 device=CFG.device, \n",
    "                                                 epoch=epoch, whf=whf_loss)\n",
    "        val_dice, val_jaccard = val_scores\n",
    "    \n",
    "        history['Train Loss'].append(train_loss)\n",
    "        history['Valid Loss'].append(val_loss)\n",
    "        history['Valid Dice'].append(val_dice)\n",
    "        history['Valid Jaccard'].append(val_jaccard)\n",
    "        \n",
    "        # Log the metrics\n",
    "        \"\"\"\n",
    "        wandb.log({\"Train Loss\": train_loss, \n",
    "                   \"Valid Loss\": val_loss,\n",
    "                   \"Valid Dice\": val_dice,\n",
    "                   \"Valid Jaccard\": val_jaccard,\n",
    "                   \"LR\":scheduler.get_last_lr()[0]})\n",
    "        \"\"\"\n",
    "        print(f'Valid Dice: {val_dice:0.4f} | Valid Jaccard: {val_jaccard:0.4f}')\n",
    "        \n",
    "        # deep copy the model\n",
    "        if val_loss >= best_loss:\n",
    "            print(f\"Valid loss Improved ({best_loss:0.4f} ---> {val_loss:0.4f})\")\n",
    "            best_loss    = val_loss\n",
    "            best_jaccard = val_jaccard\n",
    "            best_dice = val_dice\n",
    "            best_epoch   = epoch\n",
    "            \"\"\"\n",
    "            run.summary[\"Best Dice\"]    = best_dice\n",
    "            run.summary[\"Best Jaccard\"] = best_jaccard\n",
    "            run.summary[\"Best Epoch\"]   = best_epoch\n",
    "            \"\"\"\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            save_path = f\"best_epoch-{fold:02d}.bin\"\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            # Save a model file from the current directory\n",
    "            # wandb.save(PATH)\n",
    "            print(f\"Model Saved\")\n",
    "            \n",
    "        last_model_wts = copy.deepcopy(model.state_dict())\n",
    "        model_path = f\"last_epoch-{fold:02d}.bin\"\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "        print(); print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best Loss: {:.4f}\".format(best_loss))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe660c4-7b0a-4994-bfa9-71e80756fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CFG.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CFG.T_max, \n",
    "                                                   eta_min=CFG.min_lr)\n",
    "    elif CFG.scheduler == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CFG.T_0, \n",
    "                                                             eta_min=CFG.min_lr)\n",
    "    elif CFG.scheduler == 'ReduceLROnPlateau':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                   mode='min',\n",
    "                                                   factor=0.1,\n",
    "                                                   patience=7,\n",
    "                                                   threshold=0.0001,\n",
    "                                                   min_lr=CFG.min_lr,)\n",
    "    elif CFG.scheduer == 'ExponentialLR':\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.85)\n",
    "    elif CFG.scheduler == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c649ee-6045-4480-8f48-09f66093ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "whf_loss = WeightedHausdorffLoss(3, [val // CFG.whf_pool_size for val in CFG.image_size], alpha=-5.0, device=CFG.device)\n",
    "for fold in range(1):\n",
    "    print(f'#'*15)\n",
    "    print(f'### Fold: {fold}')\n",
    "    print(f'#'*15)\n",
    "    \"\"\"\n",
    "    run = wandb.init(project='uw-maddison-gi-tract', \n",
    "                     config={k:v for k, v in dict(vars(CFG)).items() if '__' not in k},\n",
    "                     anonymous=anonymous,\n",
    "                     name=f\"fold-{fold}|dim-{CFG.img_size[0]}x{CFG.img_size[1]}|model-{CFG.model_name}\",\n",
    "                     group=CFG.comment,\n",
    "                    )\n",
    "    \"\"\"\n",
    "    train_loader, valid_loader = prepare_loaders(df_train, fold=fold, debug=CFG.debug)\n",
    "    # model     = build_model()\n",
    "    model = load_model(f\"best_epoch-{fold:02d}.bin\")\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
    "    scheduler = fetch_scheduler(optimizer)\n",
    "    model, history = run_training(fold, model, whf_loss, optimizer, scheduler,\n",
    "                                  device=CFG.device,\n",
    "                                  num_epochs=CFG.epochs)\n",
    "    \"\"\"\n",
    "    run.finish()\n",
    "    display(ipd.IFrame(run.url, width=1000, height=720))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd4e5d6-4204-43ac-8f97-c5da1b33ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img, mask=None):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "#     img = clahe.apply(img)\n",
    "#     plt.figure(figsize=(10,10))\n",
    "    plt.imshow(img, cmap='bone')\n",
    "    \n",
    "    if mask is not None:\n",
    "        # plt.imshow(np.ma.masked_where(mask!=1, mask), alpha=0.5, cmap='autumn')\n",
    "        plt.imshow(mask, alpha=0.5)\n",
    "        handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n",
    "        labels = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n",
    "        plt.legend(handles,labels)\n",
    "    plt.axis('off')\n",
    "\n",
    "def plot_batch(imgs, msks, depth, size=3):\n",
    "    plt.figure(figsize=(5*5, 5))\n",
    "    for idx in range(size):\n",
    "        plt.subplot(1, 5, idx+1)\n",
    "        img = imgs[idx, :, :, :, depth].permute((1, 2, 0)).numpy()*255.0\n",
    "        img = img.astype('uint8')\n",
    "        msk = msks[idx, :, :, :, depth].permute((1, 2, 0)).numpy()*255.0\n",
    "        print(msk.sum())\n",
    "        show_img(img, msk)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb8edfe-626a-45e7-9965-55f21fafc4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "test_dataset = tio.SubjectsDataset(\n",
    "        [get_subject(row['case_day'], row['image_path'], row['mask_path']) for _, row in df_train.query(\"fold==0\").sample(frac=1.0).iterrows()], \n",
    "        transform=data_transforms['valid']\n",
    "    )\n",
    "\n",
    "#test_loader  = DataLoader(test_dataset, batch_size=1, num_workers=0, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8a2aac-1a30-46f4-841a-b762ae36b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = test_dataset[11]\n",
    "image = subject['scan'][tio.DATA]\n",
    "image = image.unsqueeze(0).to(CFG.device, dtype=torch.float)\n",
    "mask = subject['label'][tio.DATA]\n",
    "mask = mask.unsqueeze(0).to(CFG.device, dtype=torch.float)\n",
    "\n",
    "pred = None\n",
    "fold=0\n",
    "model = load_model(f\"best_epoch-{fold:02d}.bin\")\n",
    "with torch.no_grad():\n",
    "    pred = model(image)\n",
    "    pred = (pred>0.2).double()\n",
    "    \n",
    "image  = image.cpu().detach()\n",
    "mask = mask.cpu().detach()\n",
    "pred = pred.cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f33388-8f26-461e-a6f2-9f7086d4f6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aac27a-85ef-4d00-a756-1ea954e8ed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth=66\n",
    "plot_batch(image, pred, depth=depth, size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6c3f31-fada-400d-a7e1-f2c20ae03a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_batch(image, mask, depth=depth, size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ae133c-c1b3-4e50-ac44-01b152e32426",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Linear(2,1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
    "scheduler = fetch_scheduler(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f675b1f-308a-4d82-83e0-e1989f088d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = []\n",
    "steps = []\n",
    "for i in range(16 * 300):\n",
    "    optimizer.step()\n",
    "    if i % 300 == 0:\n",
    "        lrs.append(optimizer.param_groups[0]['lr'])\n",
    "        steps.append(i)\n",
    "    scheduler.step()\n",
    "\n",
    "    \n",
    "plt.plot(steps, lrs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
